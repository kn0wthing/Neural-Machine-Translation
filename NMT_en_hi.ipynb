{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "0ZPGidHfSYOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Hindi_English_Truncated_Corpus.csv')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:31:25.044877Z",
          "iopub.execute_input": "2023-03-04T19:31:25.045468Z",
          "iopub.status.idle": "2023-03-04T19:31:26.558618Z",
          "shell.execute_reply.started": "2023-03-04T19:31:25.045425Z",
          "shell.execute_reply": "2023-03-04T19:31:26.557680Z"
        },
        "trusted": true,
        "id": "JyT7fYMuSP9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:31:26.559963Z",
          "iopub.execute_input": "2023-03-04T19:31:26.560396Z",
          "iopub.status.idle": "2023-03-04T19:31:26.583009Z",
          "shell.execute_reply.started": "2023-03-04T19:31:26.560351Z",
          "shell.execute_reply": "2023-03-04T19:31:26.581774Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "bEJDx0NySP9N",
        "outputId": "265af6ac-93ba-4a33-d024-d187b4656764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      source                                   english_sentence  \\\n",
              "0        ted  politicians do not have permission to do what ...   \n",
              "1        ted         I'd like to tell you about one such child,   \n",
              "2  indic2012  This percentage is even greater than the perce...   \n",
              "3        ted  what we really mean is that they're bad at not...   \n",
              "4  indic2012  .The ending portion of these Vedas is called U...   \n",
              "5      tides  The then Governor of Kashmir resisted transfer...   \n",
              "6  indic2012  In this lies the circumstances of people befor...   \n",
              "7        ted   And who are we to say, even, that they are wrong   \n",
              "8  indic2012  “”Global Warming“” refer to warming caused in ...   \n",
              "9      tides  You may want your child to go to a school that...   \n",
              "\n",
              "                                      hindi_sentence  \n",
              "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
              "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
              "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
              "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
              "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  \n",
              "5  कश्मीर के तत्कालीन गवर्नर ने इस हस्तांतरण का व...  \n",
              "6   इसमें तुमसे पूर्व गुज़रे हुए लोगों के हालात हैं।  \n",
              "7   और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं  \n",
              "8  ग्लोबल वॉर्मिंग से आशय हाल ही के दशकों में हुई...  \n",
              "9  हो सकता है कि आप चाहते हों कि आप का नऋर्नमेनटे...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1595c55-1dce-4829-b0b6-2fbf331125a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>english_sentence</th>\n",
              "      <th>hindi_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ted</td>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ted</td>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ted</td>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>.The ending portion of these Vedas is called U...</td>\n",
              "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tides</td>\n",
              "      <td>The then Governor of Kashmir resisted transfer...</td>\n",
              "      <td>कश्मीर के तत्कालीन गवर्नर ने इस हस्तांतरण का व...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>In this lies the circumstances of people befor...</td>\n",
              "      <td>इसमें तुमसे पूर्व गुज़रे हुए लोगों के हालात हैं।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ted</td>\n",
              "      <td>And who are we to say, even, that they are wrong</td>\n",
              "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>indic2012</td>\n",
              "      <td>“”Global Warming“” refer to warming caused in ...</td>\n",
              "      <td>ग्लोबल वॉर्मिंग से आशय हाल ही के दशकों में हुई...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>tides</td>\n",
              "      <td>You may want your child to go to a school that...</td>\n",
              "      <td>हो सकता है कि आप चाहते हों कि आप का नऋर्नमेनटे...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1595c55-1dce-4829-b0b6-2fbf331125a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1595c55-1dce-4829-b0b6-2fbf331125a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1595c55-1dce-4829-b0b6-2fbf331125a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:31:26.584723Z",
          "iopub.execute_input": "2023-03-04T19:31:26.585325Z",
          "iopub.status.idle": "2023-03-04T19:31:26.648621Z",
          "shell.execute_reply.started": "2023-03-04T19:31:26.585275Z",
          "shell.execute_reply": "2023-03-04T19:31:26.647434Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD-uEcUGSP9N",
        "outputId": "715b32e5-0560-4e0a-e672-999be66272c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 127607 entries, 0 to 127606\n",
            "Data columns (total 3 columns):\n",
            " #   Column            Non-Null Count   Dtype \n",
            "---  ------            --------------   ----- \n",
            " 0   source            127607 non-null  object\n",
            " 1   english_sentence  127605 non-null  object\n",
            " 2   hindi_sentence    127607 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 2.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "AU2z9MxWSP9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['english_sentence_mark'] = data['english_sentence'].apply(lambda x : '<sos> '+str(x)+' <eos>')\n",
        "data['hindi_sentence_mark'] = data['hindi_sentence'].apply(lambda x : '<sos> '+str(x)+' <eos>')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:32:08.738358Z",
          "iopub.execute_input": "2023-03-04T19:32:08.738833Z",
          "iopub.status.idle": "2023-03-04T19:32:08.939766Z",
          "shell.execute_reply.started": "2023-03-04T19:32:08.738795Z",
          "shell.execute_reply": "2023-03-04T19:32:08.938851Z"
        },
        "trusted": true,
        "id": "CiHfgYlsSP9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "unk_token = '<unk>'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:32:13.162782Z",
          "iopub.execute_input": "2023-03-04T19:32:13.163475Z",
          "iopub.status.idle": "2023-03-04T19:32:13.168012Z",
          "shell.execute_reply.started": "2023-03-04T19:32:13.163429Z",
          "shell.execute_reply": "2023-03-04T19:32:13.167073Z"
        },
        "trusted": true,
        "id": "Vm4kCEppSP9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenisation"
      ],
      "metadata": {
        "id": "On9MvyXpSP9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:32:22.097442Z",
          "iopub.execute_input": "2023-03-04T19:32:22.098670Z",
          "iopub.status.idle": "2023-03-04T19:32:26.955921Z",
          "shell.execute_reply.started": "2023-03-04T19:32:22.098621Z",
          "shell.execute_reply": "2023-03-04T19:32:26.954757Z"
        },
        "trusted": true,
        "id": "aYZlwB14SP9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer_en = tf.keras.layers.TextVectorization(\n",
        " output_mode='int',\n",
        " output_sequence_length=256)\n",
        "\n",
        "vectorize_layer_hi = tf.keras.layers.TextVectorization(\n",
        " output_mode='int',\n",
        " output_sequence_length=256)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:32:26.957491Z",
          "iopub.execute_input": "2023-03-04T19:32:26.958127Z",
          "iopub.status.idle": "2023-03-04T19:32:28.016725Z",
          "shell.execute_reply.started": "2023-03-04T19:32:26.958092Z",
          "shell.execute_reply": "2023-03-04T19:32:28.015581Z"
        },
        "trusted": true,
        "id": "cJsmWvvHSP9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer_en.adapt(data['english_sentence_mark'])\n",
        "vectorize_layer_hi.adapt(data['hindi_sentence_mark'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:32:28.018228Z",
          "iopub.execute_input": "2023-03-04T19:32:28.018868Z",
          "iopub.status.idle": "2023-03-04T19:32:38.467532Z",
          "shell.execute_reply.started": "2023-03-04T19:32:28.018828Z",
          "shell.execute_reply": "2023-03-04T19:32:38.466672Z"
        },
        "trusted": true,
        "id": "5w4kBp1kSP9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER_LEN = 256\n",
        "DECODER_LEN = 256\n",
        "BATCH_SIZE = 10\n",
        "BUFFER_SIZE = BATCH_SIZE*4"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:32:42.299446Z",
          "iopub.execute_input": "2023-03-04T19:32:42.300439Z",
          "iopub.status.idle": "2023-03-04T19:32:42.304276Z",
          "shell.execute_reply.started": "2023-03-04T19:32:42.300397Z",
          "shell.execute_reply": "2023-03-04T19:32:42.303582Z"
        },
        "trusted": true,
        "id": "IdP3QE27SP9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENCODER_VOCAB  = len(vectorize_layer_en.get_vocabulary())\n",
        "DECODER_VOCAB = len(vectorize_layer_hi.get_vocabulary())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:32:42.841122Z",
          "iopub.execute_input": "2023-03-04T19:32:42.842185Z",
          "iopub.status.idle": "2023-03-04T19:32:43.338129Z",
          "shell.execute_reply.started": "2023-03-04T19:32:42.842144Z",
          "shell.execute_reply": "2023-03-04T19:32:43.337198Z"
        },
        "trusted": true,
        "id": "FFbW_dyHSP9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.Input(shape = (1,),dtype = tf.string),\n",
        "    vectorize_layer_en]\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:32:51.101717Z",
          "iopub.execute_input": "2023-03-04T19:32:51.102150Z",
          "iopub.status.idle": "2023-03-04T19:32:51.140429Z",
          "shell.execute_reply.started": "2023-03-04T19:32:51.102117Z",
          "shell.execute_reply": "2023-03-04T19:32:51.139555Z"
        },
        "trusted": true,
        "id": "nmfZaPIESP9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(data['english_sentence_mark']) == vectorize_layer_en(data['english_sentence_mark'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:32:56.650729Z",
          "iopub.execute_input": "2023-03-04T19:32:56.651142Z",
          "iopub.status.idle": "2023-03-04T19:33:08.213516Z",
          "shell.execute_reply.started": "2023-03-04T19:32:56.651109Z",
          "shell.execute_reply": "2023-03-04T19:33:08.212424Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTWRiqamSP9P",
        "outputId": "7ee6b598-a108-4a55-d64c-e91901bd1e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3988/3988 [==============================] - 11s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(127607, 256), dtype=bool, numpy=\n",
              "array([[ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       ...,\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [ True,  True,  True, ...,  True,  True,  True]])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((vectorize_layer_en(data['english_sentence_mark']), vectorize_layer_hi(data['hindi_sentence']))).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:33:08.215174Z",
          "iopub.execute_input": "2023-03-04T19:33:08.215566Z",
          "iopub.status.idle": "2023-03-04T19:33:09.863691Z",
          "shell.execute_reply.started": "2023-03-04T19:33:08.215532Z",
          "shell.execute_reply": "2023-03-04T19:33:09.862777Z"
        },
        "trusted": true,
        "id": "85bUFKm0SP9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "QEE0WhFoSP9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(position, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis],\n",
        "        np.arange(d_model)[np.newaxis, :],\n",
        "        d_model\n",
        "    )\n",
        "\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:33:53.142570Z",
          "iopub.execute_input": "2023-03-04T19:33:53.143071Z",
          "iopub.status.idle": "2023-03-04T19:33:53.156394Z",
          "shell.execute_reply.started": "2023-03-04T19:33:53.143020Z",
          "shell.execute_reply": "2023-03-04T19:33:53.154940Z"
        },
        "trusted": true,
        "id": "NrrpVLriSP9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "        \n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "            \n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:33:58.846837Z",
          "iopub.execute_input": "2023-03-04T19:33:58.847660Z",
          "iopub.status.idle": "2023-03-04T19:33:58.860794Z",
          "shell.execute_reply.started": "2023-03-04T19:33:58.847605Z",
          "shell.execute_reply": "2023-03-04T19:33:58.859704Z"
        },
        "trusted": true,
        "id": "Te-lE_jVSP9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:34:06.627342Z",
          "iopub.execute_input": "2023-03-04T19:34:06.627975Z",
          "iopub.status.idle": "2023-03-04T19:34:06.634994Z",
          "shell.execute_reply.started": "2023-03-04T19:34:06.627925Z",
          "shell.execute_reply": "2023-03-04T19:34:06.633923Z"
        },
        "trusted": true,
        "id": "lhqmYqRHSP9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, training, mask):\n",
        "        attn_output,_ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:34:22.348294Z",
          "iopub.execute_input": "2023-03-04T19:34:22.348738Z",
          "iopub.status.idle": "2023-03-04T19:34:22.357749Z",
          "shell.execute_reply.started": "2023-03-04T19:34:22.348702Z",
          "shell.execute_reply": "2023-03-04T19:34:22.356941Z"
        },
        "trusted": true,
        "id": "OOlNI_NGSP9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:34:40.564471Z",
          "iopub.execute_input": "2023-03-04T19:34:40.564942Z",
          "iopub.status.idle": "2023-03-04T19:34:40.576985Z",
          "shell.execute_reply.started": "2023-03-04T19:34:40.564906Z",
          "shell.execute_reply": "2023-03-04T19:34:40.575908Z"
        },
        "trusted": true,
        "id": "lNdzNeFuSP9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "    \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "        return x\n",
        "    \n",
        "class Decoder(tf.keras.layers.Layer):\n",
        "        \n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "        return x, attention_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:34:44.206083Z",
          "iopub.execute_input": "2023-03-04T19:34:44.206537Z",
          "iopub.status.idle": "2023-03-04T19:34:44.223926Z",
          "shell.execute_reply.started": "2023-03-04T19:34:44.206478Z",
          "shell.execute_reply": "2023-03-04T19:34:44.222849Z"
        },
        "trusted": true,
        "id": "zVqR-fq7SP9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output, attention_weights\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:34:47.099578Z",
          "iopub.execute_input": "2023-03-04T19:34:47.100005Z",
          "iopub.status.idle": "2023-03-04T19:34:47.108944Z",
          "shell.execute_reply.started": "2023-03-04T19:34:47.099970Z",
          "shell.execute_reply": "2023-03-04T19:34:47.107581Z"
        },
        "trusted": true,
        "id": "LT4AzaQoSP9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 128\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:34:53.174603Z",
          "iopub.execute_input": "2023-03-04T19:34:53.175036Z",
          "iopub.status.idle": "2023-03-04T19:34:53.180143Z",
          "shell.execute_reply.started": "2023-03-04T19:34:53.175003Z",
          "shell.execute_reply": "2023-03-04T19:34:53.179096Z"
        },
        "trusted": true,
        "id": "GCeeis3oSP9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:34:55.593528Z",
          "iopub.execute_input": "2023-03-04T19:34:55.593955Z",
          "iopub.status.idle": "2023-03-04T19:34:55.601686Z",
          "shell.execute_reply.started": "2023-03-04T19:34:55.593919Z",
          "shell.execute_reply": "2023-03-04T19:34:55.600597Z"
        },
        "trusted": true,
        "id": "OqRu83fNSP9R"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:35:07.771657Z",
          "iopub.execute_input": "2023-03-04T19:35:07.772121Z",
          "iopub.status.idle": "2023-03-04T19:35:07.778658Z",
          "shell.execute_reply.started": "2023-03-04T19:35:07.772082Z",
          "shell.execute_reply": "2023-03-04T19:35:07.777592Z"
        },
        "trusted": true,
        "id": "x4TgB9meSP9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "@tf.function\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def accuracy_function(real, pred):\n",
        "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:35:16.923925Z",
          "iopub.execute_input": "2023-03-04T19:35:16.924334Z",
          "iopub.status.idle": "2023-03-04T19:35:16.946320Z",
          "shell.execute_reply.started": "2023-03-04T19:35:16.924301Z",
          "shell.execute_reply": "2023-03-04T19:35:16.945348Z"
        },
        "trusted": true,
        "id": "nwnZvZQOSP9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=ENCODER_VOCAB,\n",
        "    target_vocab_size=DECODER_VOCAB,\n",
        "    pe_input=1000,\n",
        "    pe_target=1000,\n",
        "    rate=dropout_rate)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:35:24.205725Z",
          "iopub.execute_input": "2023-03-04T19:35:24.206158Z",
          "iopub.status.idle": "2023-03-04T19:35:24.345852Z",
          "shell.execute_reply.started": "2023-03-04T19:35:24.206122Z",
          "shell.execute_reply": "2023-03-04T19:35:24.344784Z"
        },
        "trusted": true,
        "id": "G9B2xMusSP9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:35:28.611655Z",
          "iopub.execute_input": "2023-03-04T19:35:28.612096Z",
          "iopub.status.idle": "2023-03-04T19:35:28.617975Z",
          "shell.execute_reply.started": "2023-03-04T19:35:28.612058Z",
          "shell.execute_reply": "2023-03-04T19:35:28.617197Z"
        },
        "trusted": true,
        "id": "K-KfouXwSP9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"checkpoints\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print ('Latest checkpoint restored!!')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:35:31.997180Z",
          "iopub.execute_input": "2023-03-04T19:35:31.998120Z",
          "iopub.status.idle": "2023-03-04T19:35:32.006354Z",
          "shell.execute_reply.started": "2023-03-04T19:35:31.998076Z",
          "shell.execute_reply": "2023-03-04T19:35:32.005571Z"
        },
        "trusted": true,
        "id": "cJU3-vfBSP9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp, tar_inp, \n",
        "            True, \n",
        "            enc_padding_mask, \n",
        "            combined_mask, \n",
        "            dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:35:36.336575Z",
          "iopub.execute_input": "2023-03-04T19:35:36.337183Z",
          "iopub.status.idle": "2023-03-04T19:35:36.344320Z",
          "shell.execute_reply.started": "2023-03-04T19:35:36.337147Z",
          "shell.execute_reply": "2023-03-04T19:35:36.343308Z"
        },
        "trusted": true,
        "id": "h5H7MIfnSP9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "  \n",
        "    for (batch, (inp, tar)) in enumerate(dataset):\n",
        "        train_step(inp, tar)\n",
        "    \n",
        "        if batch % 200 == 0:\n",
        "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "      \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "   \n",
        "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-04T19:35:43.211769Z",
          "iopub.execute_input": "2023-03-04T19:35:43.212234Z"
        },
        "trusted": true,
        "id": "0gLCrPlBSP9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(text):\n",
        "    text = eng_tokenizer.texts_to_sequences([text])\n",
        "    text = tf.keras.preprocessing.sequence.pad_sequences(text, maxlen=ENCODER_LEN, \n",
        "                                                                   padding='post', truncating='post')\n",
        "\n",
        "    encoder_input = tf.expand_dims(text[0], 0)\n",
        "\n",
        "    decoder_input = [hind_tokenizer.word_index['<sos>']]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "    for i in range(DECODER_LEN):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input, \n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == hind_tokenizer.word_index['<eos>']:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-13T14:23:59.990404Z",
          "iopub.execute_input": "2022-07-13T14:23:59.990772Z",
          "iopub.status.idle": "2022-07-13T14:23:59.999871Z",
          "shell.execute_reply.started": "2022-07-13T14:23:59.990744Z",
          "shell.execute_reply": "2022-07-13T14:23:59.999077Z"
        },
        "trusted": true,
        "id": "UXAswSLDSP9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(eng_text):\n",
        "    hind_text = evaluate(text=eng_text)[0].numpy()\n",
        "    hind_text = np.expand_dims(hind_text[1:], 0)  \n",
        "    return hind_tokenizer.sequences_to_texts(hind_text)[0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-13T14:24:03.598401Z",
          "iopub.execute_input": "2022-07-13T14:24:03.59876Z",
          "iopub.status.idle": "2022-07-13T14:24:03.603549Z",
          "shell.execute_reply.started": "2022-07-13T14:24:03.598731Z",
          "shell.execute_reply": "2022-07-13T14:24:03.602967Z"
        },
        "trusted": true,
        "id": "x6MysWYcSP9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jeUlc9W_SP9T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}